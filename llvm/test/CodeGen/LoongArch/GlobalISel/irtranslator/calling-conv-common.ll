; NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py UTC_ARGS: --version 5
; RUN: llc --mtriple=loongarch64 --target-abi=lp64s \
; RUN:    -global-isel -stop-after=irtranslator -verify-machineinstrs < %s \
; RUN:   | FileCheck -check-prefix=LA64 %s
; RUN: llc --mtriple=loongarch64 --mattr=+d --target-abi=lp64d \
; RUN:    -global-isel -stop-after=irtranslator -verify-machineinstrs < %s \
; RUN:   | FileCheck -check-prefix=LA64 %s

;; This file contains tests that should have identical output for all ABIs, i.e.
;; where no arguments are passed via floating point registers.

;; Check that on LA64, i128 is passed in a pair of GPRs.
define i64 @callee_i128_in_regs(i64 %a, i128 %b) nounwind {
  ; LA64-LABEL: name: callee_i128_in_regs
  ; LA64: bb.1 (%ir-block.0):
  ; LA64-NEXT:   liveins: $r4, $r5, $r6
  ; LA64-NEXT: {{  $}}
  ; LA64-NEXT:   [[COPY:%[0-9]+]]:_(s64) = COPY $r4
  ; LA64-NEXT:   [[COPY1:%[0-9]+]]:_(s64) = COPY $r5
  ; LA64-NEXT:   [[COPY2:%[0-9]+]]:_(s64) = COPY $r6
  ; LA64-NEXT:   [[MV:%[0-9]+]]:_(s128) = G_MERGE_VALUES [[COPY1]](s64), [[COPY2]](s64)
  ; LA64-NEXT:   [[TRUNC:%[0-9]+]]:_(s64) = G_TRUNC [[MV]](s128)
  ; LA64-NEXT:   [[ADD:%[0-9]+]]:_(s64) = G_ADD [[COPY]], [[TRUNC]]
  ; LA64-NEXT:   $r4 = COPY [[ADD]](s64)
  ; LA64-NEXT:   PseudoRET implicit $r4
  %b_trunc = trunc i128 %b to i64
  %1 = add i64 %a, %b_trunc
  ret i64 %1
}

define i64 @caller_i128_in_regs() nounwind {
  ; LA64-LABEL: name: caller_i128_in_regs
  ; LA64: bb.1 (%ir-block.0):
  ; LA64-NEXT:   [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 1
  ; LA64-NEXT:   [[C1:%[0-9]+]]:_(s128) = G_CONSTANT i128 2
  ; LA64-NEXT:   [[UV:%[0-9]+]]:_(s64), [[UV1:%[0-9]+]]:_(s64) = G_UNMERGE_VALUES [[C1]](s128)
  ; LA64-NEXT:   $r4 = COPY [[C]](s64)
  ; LA64-NEXT:   $r5 = COPY [[UV]](s64)
  ; LA64-NEXT:   $r6 = COPY [[UV1]](s64)
  ; LA64-NEXT:   PseudoCALL target-flags(loongarch-call-plt) @callee_i128_in_regs, implicit-def $r1, implicit $r4, implicit $r5, implicit $r6, implicit-def $r4
  ; LA64-NEXT:   [[COPY:%[0-9]+]]:_(s64) = COPY $r4
  ; LA64-NEXT:   $r4 = COPY [[COPY]](s64)
  ; LA64-NEXT:   PseudoRET implicit $r4
  %1 = call i64 @callee_i128_in_regs(i64 1, i128 2)
  ret i64 %1
}

;; Check that the stack is used once the GPRs are exhausted.
define i64 @callee_many_scalars(i8 %a, i16 %b, i32 %c, i64 %d, i128 %e, i64 %f, i128 %g, i64 %h) nounwind {
  ; LA64-LABEL: name: callee_many_scalars
  ; LA64: bb.1 (%ir-block.0):
  ; LA64-NEXT:   liveins: $r4, $r5, $r6, $r7, $r8, $r9, $r10, $r11
  ; LA64-NEXT: {{  $}}
  ; LA64-NEXT:   [[COPY:%[0-9]+]]:_(s64) = COPY $r4
  ; LA64-NEXT:   [[TRUNC:%[0-9]+]]:_(s8) = G_TRUNC [[COPY]](s64)
  ; LA64-NEXT:   [[COPY1:%[0-9]+]]:_(s64) = COPY $r5
  ; LA64-NEXT:   [[TRUNC1:%[0-9]+]]:_(s16) = G_TRUNC [[COPY1]](s64)
  ; LA64-NEXT:   [[COPY2:%[0-9]+]]:_(s64) = COPY $r6
  ; LA64-NEXT:   [[TRUNC2:%[0-9]+]]:_(s32) = G_TRUNC [[COPY2]](s64)
  ; LA64-NEXT:   [[COPY3:%[0-9]+]]:_(s64) = COPY $r7
  ; LA64-NEXT:   [[COPY4:%[0-9]+]]:_(s64) = COPY $r8
  ; LA64-NEXT:   [[COPY5:%[0-9]+]]:_(s64) = COPY $r9
  ; LA64-NEXT:   [[MV:%[0-9]+]]:_(s128) = G_MERGE_VALUES [[COPY4]](s64), [[COPY5]](s64)
  ; LA64-NEXT:   [[COPY6:%[0-9]+]]:_(s64) = COPY $r10
  ; LA64-NEXT:   [[COPY7:%[0-9]+]]:_(s64) = COPY $r11
  ; LA64-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %fixed-stack.1
  ; LA64-NEXT:   [[LOAD:%[0-9]+]]:_(s64) = G_LOAD [[FRAME_INDEX]](p0) :: (load (s64) from %fixed-stack.1, align 16)
  ; LA64-NEXT:   [[MV1:%[0-9]+]]:_(s128) = G_MERGE_VALUES [[COPY7]](s64), [[LOAD]](s64)
  ; LA64-NEXT:   [[FRAME_INDEX1:%[0-9]+]]:_(p0) = G_FRAME_INDEX %fixed-stack.0
  ; LA64-NEXT:   [[LOAD1:%[0-9]+]]:_(s64) = G_LOAD [[FRAME_INDEX1]](p0) :: (load (s64) from %fixed-stack.0)
  ; LA64-NEXT:   [[ZEXT:%[0-9]+]]:_(s64) = G_ZEXT [[TRUNC]](s8)
  ; LA64-NEXT:   [[ZEXT1:%[0-9]+]]:_(s64) = G_ZEXT [[TRUNC1]](s16)
  ; LA64-NEXT:   [[ZEXT2:%[0-9]+]]:_(s64) = G_ZEXT [[TRUNC2]](s32)
  ; LA64-NEXT:   [[ADD:%[0-9]+]]:_(s64) = G_ADD [[ZEXT]], [[ZEXT1]]
  ; LA64-NEXT:   [[ADD1:%[0-9]+]]:_(s64) = G_ADD [[ADD]], [[ZEXT2]]
  ; LA64-NEXT:   [[ADD2:%[0-9]+]]:_(s64) = G_ADD [[ADD1]], [[COPY3]]
  ; LA64-NEXT:   [[ICMP:%[0-9]+]]:_(s1) = G_ICMP intpred(eq), [[MV]](s128), [[MV1]]
  ; LA64-NEXT:   [[ZEXT3:%[0-9]+]]:_(s64) = G_ZEXT [[ICMP]](s1)
  ; LA64-NEXT:   [[ADD3:%[0-9]+]]:_(s64) = G_ADD [[ZEXT3]], [[ADD2]]
  ; LA64-NEXT:   [[ADD4:%[0-9]+]]:_(s64) = G_ADD [[ADD3]], [[COPY6]]
  ; LA64-NEXT:   [[ADD5:%[0-9]+]]:_(s64) = G_ADD [[ADD4]], [[LOAD1]]
  ; LA64-NEXT:   $r4 = COPY [[ADD5]](s64)
  ; LA64-NEXT:   PseudoRET implicit $r4
  %a_ext = zext i8 %a to i64
  %b_ext = zext i16 %b to i64
  %c_ext = zext i32 %c to i64
  %1 = add i64 %a_ext, %b_ext
  %2 = add i64 %1, %c_ext
  %3 = add i64 %2, %d
  %4 = icmp eq i128 %e, %g
  %5 = zext i1 %4 to i64
  %6 = add i64 %5, %3
  %7 = add i64 %6, %f
  %8 = add i64 %7, %h
  ret i64 %8
}

define i64 @caller_many_scalars() nounwind {
  ; LA64-LABEL: name: caller_many_scalars
  ; LA64: bb.1 (%ir-block.0):
  ; LA64-NEXT:   [[C:%[0-9]+]]:_(s8) = G_CONSTANT i8 1
  ; LA64-NEXT:   [[C1:%[0-9]+]]:_(s16) = G_CONSTANT i16 2
  ; LA64-NEXT:   [[C2:%[0-9]+]]:_(s32) = G_CONSTANT i32 3
  ; LA64-NEXT:   [[C3:%[0-9]+]]:_(s64) = G_CONSTANT i64 4
  ; LA64-NEXT:   [[C4:%[0-9]+]]:_(s128) = G_CONSTANT i128 5
  ; LA64-NEXT:   [[C5:%[0-9]+]]:_(s64) = G_CONSTANT i64 6
  ; LA64-NEXT:   [[C6:%[0-9]+]]:_(s128) = G_CONSTANT i128 7
  ; LA64-NEXT:   [[C7:%[0-9]+]]:_(s64) = G_CONSTANT i64 8
  ; LA64-NEXT:   [[ANYEXT:%[0-9]+]]:_(s64) = G_ANYEXT [[C]](s8)
  ; LA64-NEXT:   [[ANYEXT1:%[0-9]+]]:_(s64) = G_ANYEXT [[C1]](s16)
  ; LA64-NEXT:   [[ANYEXT2:%[0-9]+]]:_(s64) = G_ANYEXT [[C2]](s32)
  ; LA64-NEXT:   [[UV:%[0-9]+]]:_(s64), [[UV1:%[0-9]+]]:_(s64) = G_UNMERGE_VALUES [[C4]](s128)
  ; LA64-NEXT:   [[UV2:%[0-9]+]]:_(s64), [[UV3:%[0-9]+]]:_(s64) = G_UNMERGE_VALUES [[C6]](s128)
  ; LA64-NEXT:   [[COPY:%[0-9]+]]:_(p0) = COPY $r3
  ; LA64-NEXT:   [[C8:%[0-9]+]]:_(s64) = G_CONSTANT i64 0
  ; LA64-NEXT:   [[PTR_ADD:%[0-9]+]]:_(p0) = G_PTR_ADD [[COPY]], [[C8]](s64)
  ; LA64-NEXT:   G_STORE [[UV3]](s64), [[PTR_ADD]](p0) :: (store (s64) into stack, align 16)
  ; LA64-NEXT:   [[C9:%[0-9]+]]:_(s64) = G_CONSTANT i64 8
  ; LA64-NEXT:   [[PTR_ADD1:%[0-9]+]]:_(p0) = G_PTR_ADD [[COPY]], [[C9]](s64)
  ; LA64-NEXT:   G_STORE [[C7]](s64), [[PTR_ADD1]](p0) :: (store (s64) into stack + 8)
  ; LA64-NEXT:   $r4 = COPY [[ANYEXT]](s64)
  ; LA64-NEXT:   $r5 = COPY [[ANYEXT1]](s64)
  ; LA64-NEXT:   $r6 = COPY [[ANYEXT2]](s64)
  ; LA64-NEXT:   $r7 = COPY [[C3]](s64)
  ; LA64-NEXT:   $r8 = COPY [[UV]](s64)
  ; LA64-NEXT:   $r9 = COPY [[UV1]](s64)
  ; LA64-NEXT:   $r10 = COPY [[C5]](s64)
  ; LA64-NEXT:   $r11 = COPY [[UV2]](s64)
  ; LA64-NEXT:   PseudoCALL target-flags(loongarch-call-plt) @callee_many_scalars, implicit-def $r1, implicit $r4, implicit $r5, implicit $r6, implicit $r7, implicit $r8, implicit $r9, implicit $r10, implicit $r11, implicit-def $r4
  ; LA64-NEXT:   [[COPY1:%[0-9]+]]:_(s64) = COPY $r4
  ; LA64-NEXT:   $r4 = COPY [[COPY1]](s64)
  ; LA64-NEXT:   PseudoRET implicit $r4
  %1 = call i64 @callee_many_scalars(i8 1, i16 2, i32 3, i64 4, i128 5, i64 6, i128 7, i64 8)
  ret i64 %1
}

;; Check that i256 is passed indirectly.

define i64 @callee_large_scalars(i256 %a, i256 %b) nounwind {
  ; LA64-LABEL: name: callee_large_scalars
  ; LA64: bb.1 (%ir-block.0):
  ; LA64-NEXT:   liveins: $r4, $r5
  ; LA64-NEXT: {{  $}}
  ; LA64-NEXT:   [[COPY:%[0-9]+]]:_(p0) = COPY $r4
  ; LA64-NEXT:   [[LOAD:%[0-9]+]]:_(s256) = G_LOAD [[COPY]](p0) :: (load (s256), align 16)
  ; LA64-NEXT:   [[COPY1:%[0-9]+]]:_(p0) = COPY $r5
  ; LA64-NEXT:   [[LOAD1:%[0-9]+]]:_(s256) = G_LOAD [[COPY1]](p0) :: (load (s256), align 16)
  ; LA64-NEXT:   [[ICMP:%[0-9]+]]:_(s1) = G_ICMP intpred(eq), [[LOAD]](s256), [[LOAD1]]
  ; LA64-NEXT:   [[ZEXT:%[0-9]+]]:_(s64) = G_ZEXT [[ICMP]](s1)
  ; LA64-NEXT:   $r4 = COPY [[ZEXT]](s64)
  ; LA64-NEXT:   PseudoRET implicit $r4
  %1 = icmp eq i256 %a, %b
  %2 = zext i1 %1 to i64
  ret i64 %2
}

define i64 @caller_large_scalars() nounwind {
  ; LA64-LABEL: name: caller_large_scalars
  ; LA64: bb.1 (%ir-block.0):
  ; LA64-NEXT:   [[C:%[0-9]+]]:_(s256) = G_CONSTANT i256 1
  ; LA64-NEXT:   [[C1:%[0-9]+]]:_(s256) = G_CONSTANT i256 2
  ; LA64-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0
  ; LA64-NEXT:   G_STORE [[C]](s256), [[FRAME_INDEX]](p0) :: (store (s256) into %stack.0, align 16)
  ; LA64-NEXT:   [[FRAME_INDEX1:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.1
  ; LA64-NEXT:   G_STORE [[C1]](s256), [[FRAME_INDEX1]](p0) :: (store (s256) into %stack.1, align 16)
  ; LA64-NEXT:   $r4 = COPY [[FRAME_INDEX]](p0)
  ; LA64-NEXT:   $r5 = COPY [[FRAME_INDEX1]](p0)
  ; LA64-NEXT:   PseudoCALL target-flags(loongarch-call-plt) @callee_large_scalars, implicit-def $r1, implicit $r4, implicit $r5, implicit-def $r4
  ; LA64-NEXT:   [[COPY:%[0-9]+]]:_(s64) = COPY $r4
  ; LA64-NEXT:   $r4 = COPY [[COPY]](s64)
  ; LA64-NEXT:   PseudoRET implicit $r4
  %1 = call i64 @callee_large_scalars(i256 1, i256 2)
  ret i64 %1
}

;; Check that arguments larger than 2*GRLen are handled correctly when their
;; address is passed on the stack rather than in memory.

;; Must keep define on a single line due to an update_llc_test_checks.py limitation
define i64 @callee_large_scalars_exhausted_regs(i64 %a, i64 %b, i64 %c, i64 %d, i64 %e, i64 %f, i64 %g, i256 %h, i64 %i, i256 %j) nounwind {
  ; LA64-LABEL: name: callee_large_scalars_exhausted_regs
  ; LA64: bb.1 (%ir-block.0):
  ; LA64-NEXT:   liveins: $r4, $r5, $r6, $r7, $r8, $r9, $r10, $r11
  ; LA64-NEXT: {{  $}}
  ; LA64-NEXT:   [[COPY:%[0-9]+]]:_(s64) = COPY $r4
  ; LA64-NEXT:   [[COPY1:%[0-9]+]]:_(s64) = COPY $r5
  ; LA64-NEXT:   [[COPY2:%[0-9]+]]:_(s64) = COPY $r6
  ; LA64-NEXT:   [[COPY3:%[0-9]+]]:_(s64) = COPY $r7
  ; LA64-NEXT:   [[COPY4:%[0-9]+]]:_(s64) = COPY $r8
  ; LA64-NEXT:   [[COPY5:%[0-9]+]]:_(s64) = COPY $r9
  ; LA64-NEXT:   [[COPY6:%[0-9]+]]:_(s64) = COPY $r10
  ; LA64-NEXT:   [[COPY7:%[0-9]+]]:_(p0) = COPY $r11
  ; LA64-NEXT:   [[LOAD:%[0-9]+]]:_(s256) = G_LOAD [[COPY7]](p0) :: (load (s256), align 16)
  ; LA64-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %fixed-stack.1
  ; LA64-NEXT:   [[LOAD1:%[0-9]+]]:_(s64) = G_LOAD [[FRAME_INDEX]](p0) :: (load (s64) from %fixed-stack.1, align 16)
  ; LA64-NEXT:   [[FRAME_INDEX1:%[0-9]+]]:_(p0) = G_FRAME_INDEX %fixed-stack.0
  ; LA64-NEXT:   [[LOAD2:%[0-9]+]]:_(p0) = G_LOAD [[FRAME_INDEX1]](p0) :: (load (p0) from %fixed-stack.0)
  ; LA64-NEXT:   [[LOAD3:%[0-9]+]]:_(s256) = G_LOAD [[LOAD2]](p0) :: (load (s256), align 16)
  ; LA64-NEXT:   [[ICMP:%[0-9]+]]:_(s1) = G_ICMP intpred(eq), [[LOAD]](s256), [[LOAD3]]
  ; LA64-NEXT:   [[ZEXT:%[0-9]+]]:_(s64) = G_ZEXT [[ICMP]](s1)
  ; LA64-NEXT:   $r4 = COPY [[ZEXT]](s64)
  ; LA64-NEXT:   PseudoRET implicit $r4
  %1 = icmp eq i256 %h, %j
  %2 = zext i1 %1 to i64
  ret i64 %2
}

define i64 @caller_large_scalars_exhausted_regs() nounwind {
  ; LA64-LABEL: name: caller_large_scalars_exhausted_regs
  ; LA64: bb.1 (%ir-block.0):
  ; LA64-NEXT:   [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 1
  ; LA64-NEXT:   [[C1:%[0-9]+]]:_(s64) = G_CONSTANT i64 2
  ; LA64-NEXT:   [[C2:%[0-9]+]]:_(s64) = G_CONSTANT i64 3
  ; LA64-NEXT:   [[C3:%[0-9]+]]:_(s64) = G_CONSTANT i64 4
  ; LA64-NEXT:   [[C4:%[0-9]+]]:_(s64) = G_CONSTANT i64 5
  ; LA64-NEXT:   [[C5:%[0-9]+]]:_(s64) = G_CONSTANT i64 6
  ; LA64-NEXT:   [[C6:%[0-9]+]]:_(s64) = G_CONSTANT i64 7
  ; LA64-NEXT:   [[C7:%[0-9]+]]:_(s256) = G_CONSTANT i256 8
  ; LA64-NEXT:   [[C8:%[0-9]+]]:_(s64) = G_CONSTANT i64 9
  ; LA64-NEXT:   [[C9:%[0-9]+]]:_(s256) = G_CONSTANT i256 10
  ; LA64-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0
  ; LA64-NEXT:   G_STORE [[C7]](s256), [[FRAME_INDEX]](p0) :: (store (s256) into %stack.0, align 16)
  ; LA64-NEXT:   [[COPY:%[0-9]+]]:_(p0) = COPY $r3
  ; LA64-NEXT:   [[C10:%[0-9]+]]:_(s64) = G_CONSTANT i64 0
  ; LA64-NEXT:   [[PTR_ADD:%[0-9]+]]:_(p0) = G_PTR_ADD [[COPY]], [[C10]](s64)
  ; LA64-NEXT:   G_STORE [[C8]](s64), [[PTR_ADD]](p0) :: (store (s64) into stack, align 16)
  ; LA64-NEXT:   [[FRAME_INDEX1:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.1
  ; LA64-NEXT:   G_STORE [[C9]](s256), [[FRAME_INDEX1]](p0) :: (store (s256) into %stack.1, align 16)
  ; LA64-NEXT:   [[C11:%[0-9]+]]:_(s64) = G_CONSTANT i64 8
  ; LA64-NEXT:   [[PTR_ADD1:%[0-9]+]]:_(p0) = G_PTR_ADD [[COPY]], [[C11]](s64)
  ; LA64-NEXT:   G_STORE [[FRAME_INDEX1]](p0), [[PTR_ADD1]](p0) :: (store (p0) into stack + 8)
  ; LA64-NEXT:   $r4 = COPY [[C]](s64)
  ; LA64-NEXT:   $r5 = COPY [[C1]](s64)
  ; LA64-NEXT:   $r6 = COPY [[C2]](s64)
  ; LA64-NEXT:   $r7 = COPY [[C3]](s64)
  ; LA64-NEXT:   $r8 = COPY [[C4]](s64)
  ; LA64-NEXT:   $r9 = COPY [[C5]](s64)
  ; LA64-NEXT:   $r10 = COPY [[C6]](s64)
  ; LA64-NEXT:   $r11 = COPY [[FRAME_INDEX]](p0)
  ; LA64-NEXT:   PseudoCALL target-flags(loongarch-call-plt) @callee_large_scalars_exhausted_regs, implicit-def $r1, implicit $r4, implicit $r5, implicit $r6, implicit $r7, implicit $r8, implicit $r9, implicit $r10, implicit $r11, implicit-def $r4
  ; LA64-NEXT:   [[COPY1:%[0-9]+]]:_(s64) = COPY $r4
  ; LA64-NEXT:   $r4 = COPY [[COPY1]](s64)
  ; LA64-NEXT:   PseudoRET implicit $r4
  %1 = call i64 @callee_large_scalars_exhausted_regs(
      i64 1, i64 2, i64 3, i64 4, i64 5, i64 6, i64 7, i256 8, i64 9,
      i256 10)
  ret i64 %1
}

;; Check large struct arguments, which are passed byval

%struct.large = type { i64, i64, i64, i64 }

define i64 @callee_large_struct(ptr byval(%struct.large) align 8 %a) nounwind {
  ; LA64-LABEL: name: callee_large_struct
  ; LA64: bb.1 (%ir-block.0):
  ; LA64-NEXT:   liveins: $r4
  ; LA64-NEXT: {{  $}}
  ; LA64-NEXT:   [[COPY:%[0-9]+]]:_(p0) = COPY $r4
  ; LA64-NEXT:   [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 24
  ; LA64-NEXT:   %2:_(p0) = nuw nusw G_PTR_ADD [[COPY]], [[C]](s64)
  ; LA64-NEXT:   [[LOAD:%[0-9]+]]:_(s64) = G_LOAD [[COPY]](p0) :: (dereferenceable load (s64) from %ir.1)
  ; LA64-NEXT:   [[LOAD1:%[0-9]+]]:_(s64) = G_LOAD %2(p0) :: (dereferenceable load (s64) from %ir.2)
  ; LA64-NEXT:   [[ADD:%[0-9]+]]:_(s64) = G_ADD [[LOAD]], [[LOAD1]]
  ; LA64-NEXT:   $r4 = COPY [[ADD]](s64)
  ; LA64-NEXT:   PseudoRET implicit $r4
  %1 = getelementptr inbounds %struct.large, ptr %a, i64 0, i32 0
  %2 = getelementptr inbounds %struct.large, ptr %a, i64 0, i32 3
  %3 = load i64, ptr %1
  %4 = load i64, ptr %2
  %5 = add i64 %3, %4
  ret i64 %5
}

define i64 @caller_large_struct() nounwind {
  ; LA64-LABEL: name: caller_large_struct
  ; LA64: bb.1 (%ir-block.0):
  ; LA64-NEXT:   [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 1
  ; LA64-NEXT:   [[C1:%[0-9]+]]:_(s64) = G_CONSTANT i64 2
  ; LA64-NEXT:   [[C2:%[0-9]+]]:_(s64) = G_CONSTANT i64 3
  ; LA64-NEXT:   [[C3:%[0-9]+]]:_(s64) = G_CONSTANT i64 4
  ; LA64-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0.ls
  ; LA64-NEXT:   G_STORE [[C]](s64), [[FRAME_INDEX]](p0) :: (store (s64) into %ir.a1)
  ; LA64-NEXT:   [[C4:%[0-9]+]]:_(s64) = G_CONSTANT i64 8
  ; LA64-NEXT:   %3:_(p0) = nuw nusw G_PTR_ADD [[FRAME_INDEX]], [[C4]](s64)
  ; LA64-NEXT:   G_STORE [[C1]](s64), %3(p0) :: (store (s64) into %ir.b)
  ; LA64-NEXT:   [[C5:%[0-9]+]]:_(s64) = G_CONSTANT i64 16
  ; LA64-NEXT:   %6:_(p0) = nuw nusw G_PTR_ADD [[FRAME_INDEX]], [[C5]](s64)
  ; LA64-NEXT:   G_STORE [[C2]](s64), %6(p0) :: (store (s64) into %ir.c)
  ; LA64-NEXT:   [[C6:%[0-9]+]]:_(s64) = G_CONSTANT i64 24
  ; LA64-NEXT:   %9:_(p0) = nuw nusw G_PTR_ADD [[FRAME_INDEX]], [[C6]](s64)
  ; LA64-NEXT:   G_STORE [[C3]](s64), %9(p0) :: (store (s64) into %ir.d)
  ; LA64-NEXT:   $r4 = COPY [[FRAME_INDEX]](p0)
  ; LA64-NEXT:   PseudoCALL target-flags(loongarch-call-plt) @callee_large_struct, implicit-def $r1, implicit $r4, implicit-def $r4
  ; LA64-NEXT:   [[COPY:%[0-9]+]]:_(s64) = COPY $r4
  ; LA64-NEXT:   $r4 = COPY [[COPY]](s64)
  ; LA64-NEXT:   PseudoRET implicit $r4
  %ls = alloca %struct.large, align 8
  %a = getelementptr inbounds %struct.large, ptr %ls, i64 0, i32 0
  store i64 1, ptr %a
  %b = getelementptr inbounds %struct.large, ptr %ls, i64 0, i32 1
  store i64 2, ptr %b
  %c = getelementptr inbounds %struct.large, ptr %ls, i64 0, i32 2
  store i64 3, ptr %c
  %d = getelementptr inbounds %struct.large, ptr %ls, i64 0, i32 3
  store i64 4, ptr %d
  %1 = call i64 @callee_large_struct(ptr byval(%struct.large) align 8 %ls)
  ret i64 %1
}

;; Check return scalar which size is 2*GRLen.

define i128 @callee_small_scalar_ret() nounwind {
  ; LA64-LABEL: name: callee_small_scalar_ret
  ; LA64: bb.1 (%ir-block.0):
  ; LA64-NEXT:   [[C:%[0-9]+]]:_(s128) = G_CONSTANT i128 -1
  ; LA64-NEXT:   [[UV:%[0-9]+]]:_(s64), [[UV1:%[0-9]+]]:_(s64) = G_UNMERGE_VALUES [[C]](s128)
  ; LA64-NEXT:   $r4 = COPY [[UV]](s64)
  ; LA64-NEXT:   $r5 = COPY [[UV1]](s64)
  ; LA64-NEXT:   PseudoRET implicit $r4, implicit $r5
  ret i128 -1
}

define i64 @caller_small_scalar_ret() nounwind {
  ; LA64-LABEL: name: caller_small_scalar_ret
  ; LA64: bb.1 (%ir-block.0):
  ; LA64-NEXT:   [[C:%[0-9]+]]:_(s128) = G_CONSTANT i128 -2
  ; LA64-NEXT:   PseudoCALL target-flags(loongarch-call-plt) @callee_small_scalar_ret, implicit-def $r1, implicit-def $r4, implicit-def $r5
  ; LA64-NEXT:   [[COPY:%[0-9]+]]:_(s64) = COPY $r4
  ; LA64-NEXT:   [[COPY1:%[0-9]+]]:_(s64) = COPY $r5
  ; LA64-NEXT:   [[MV:%[0-9]+]]:_(s128) = G_MERGE_VALUES [[COPY]](s64), [[COPY1]](s64)
  ; LA64-NEXT:   [[ICMP:%[0-9]+]]:_(s1) = G_ICMP intpred(eq), [[C]](s128), [[MV]]
  ; LA64-NEXT:   [[ZEXT:%[0-9]+]]:_(s64) = G_ZEXT [[ICMP]](s1)
  ; LA64-NEXT:   $r4 = COPY [[ZEXT]](s64)
  ; LA64-NEXT:   PseudoRET implicit $r4
  %1 = call i128 @callee_small_scalar_ret()
  %2 = icmp eq i128 -2, %1
  %3 = zext i1 %2 to i64
  ret i64 %3
}

;; Check return struct which size is 2*GRLen.

%struct.small = type { i64, ptr }

define %struct.small @callee_small_struct_ret() nounwind {
  ; LA64-LABEL: name: callee_small_struct_ret
  ; LA64: bb.1 (%ir-block.0):
  ; LA64-NEXT:   [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 1
  ; LA64-NEXT:   [[C1:%[0-9]+]]:_(p0) = G_CONSTANT i64 0
  ; LA64-NEXT:   $r4 = COPY [[C]](s64)
  ; LA64-NEXT:   $r5 = COPY [[C1]](p0)
  ; LA64-NEXT:   PseudoRET implicit $r4, implicit $r5
  ret %struct.small { i64 1, ptr null }
}

define i64 @caller_small_struct_ret() nounwind {
  ; LA64-LABEL: name: caller_small_struct_ret
  ; LA64: bb.1 (%ir-block.0):
  ; LA64-NEXT:   PseudoCALL target-flags(loongarch-call-plt) @callee_small_struct_ret, implicit-def $r1, implicit-def $r4, implicit-def $r5
  ; LA64-NEXT:   [[COPY:%[0-9]+]]:_(s64) = COPY $r4
  ; LA64-NEXT:   [[COPY1:%[0-9]+]]:_(p0) = COPY $r5
  ; LA64-NEXT:   [[PTRTOINT:%[0-9]+]]:_(s64) = G_PTRTOINT [[COPY1]](p0)
  ; LA64-NEXT:   [[ADD:%[0-9]+]]:_(s64) = G_ADD [[COPY]], [[PTRTOINT]]
  ; LA64-NEXT:   $r4 = COPY [[ADD]](s64)
  ; LA64-NEXT:   PseudoRET implicit $r4
  %1 = call %struct.small @callee_small_struct_ret()
  %2 = extractvalue %struct.small %1, 0
  %3 = extractvalue %struct.small %1, 1
  %4 = ptrtoint ptr %3 to i64
  %5 = add i64 %2, %4
  ret i64 %5
}

;; Check return scalar which size is more than 2*GRLen.

define i256 @callee_large_scalar_ret() nounwind {
  ; LA64-LABEL: name: callee_large_scalar_ret
  ; LA64: bb.1 (%ir-block.0):
  ; LA64-NEXT:   [[C:%[0-9]+]]:_(s256) = G_CONSTANT i256 -123456789
  ; LA64-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0
  ; LA64-NEXT:   G_STORE [[C]](s256), [[FRAME_INDEX]](p0) :: (store (s256) into %stack.0, align 16)
  ; LA64-NEXT:   $r4 = COPY [[FRAME_INDEX]](p0)
  ; LA64-NEXT:   PseudoRET implicit $r4
  ret i256 -123456789
}

define void @caller_large_scalar_ret() nounwind {
  ; LA64-LABEL: name: caller_large_scalar_ret
  ; LA64: bb.1 (%ir-block.0):
  ; LA64-NEXT:   PseudoCALL target-flags(loongarch-call-plt) @callee_large_scalar_ret, implicit-def $r1, implicit-def $r4
  ; LA64-NEXT:   [[COPY:%[0-9]+]]:_(p0) = COPY $r4
  ; LA64-NEXT:   [[LOAD:%[0-9]+]]:_(s256) = G_LOAD [[COPY]](p0) :: (load (s256), align 16)
  ; LA64-NEXT:   PseudoRET
  %1 = call i256 @callee_large_scalar_ret()
  ret void
}

;; Check return struct which size is more than 2*GRLen.

define void @callee_large_struct_ret(ptr noalias sret(%struct.large) %agg.result) nounwind {
  ; LA64-LABEL: name: callee_large_struct_ret
  ; LA64: bb.1 (%ir-block.0):
  ; LA64-NEXT:   liveins: $r4
  ; LA64-NEXT: {{  $}}
  ; LA64-NEXT:   [[COPY:%[0-9]+]]:_(p0) = COPY $r4
  ; LA64-NEXT:   [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 1
  ; LA64-NEXT:   [[C1:%[0-9]+]]:_(s64) = G_CONSTANT i64 2
  ; LA64-NEXT:   [[C2:%[0-9]+]]:_(s64) = G_CONSTANT i64 3
  ; LA64-NEXT:   [[C3:%[0-9]+]]:_(s64) = G_CONSTANT i64 4
  ; LA64-NEXT:   G_STORE [[C]](s64), [[COPY]](p0) :: (store (s64) into %ir.a1, align 4)
  ; LA64-NEXT:   [[C4:%[0-9]+]]:_(s64) = G_CONSTANT i64 8
  ; LA64-NEXT:   %3:_(p0) = nuw nusw G_PTR_ADD [[COPY]], [[C4]](s64)
  ; LA64-NEXT:   G_STORE [[C1]](s64), %3(p0) :: (store (s64) into %ir.b, align 4)
  ; LA64-NEXT:   [[C5:%[0-9]+]]:_(s64) = G_CONSTANT i64 16
  ; LA64-NEXT:   %6:_(p0) = nuw nusw G_PTR_ADD [[COPY]], [[C5]](s64)
  ; LA64-NEXT:   G_STORE [[C2]](s64), %6(p0) :: (store (s64) into %ir.c, align 4)
  ; LA64-NEXT:   [[C6:%[0-9]+]]:_(s64) = G_CONSTANT i64 24
  ; LA64-NEXT:   %9:_(p0) = nuw nusw G_PTR_ADD [[COPY]], [[C6]](s64)
  ; LA64-NEXT:   G_STORE [[C3]](s64), %9(p0) :: (store (s64) into %ir.d, align 4)
  ; LA64-NEXT:   PseudoRET
  %a = getelementptr inbounds %struct.large, ptr %agg.result, i64 0, i32 0
  store i64 1, ptr %a, align 4
  %b = getelementptr inbounds %struct.large, ptr %agg.result, i64 0, i32 1
  store i64 2, ptr %b, align 4
  %c = getelementptr inbounds %struct.large, ptr %agg.result, i64 0, i32 2
  store i64 3, ptr %c, align 4
  %d = getelementptr inbounds %struct.large, ptr %agg.result, i64 0, i32 3
  store i64 4, ptr %d, align 4
  ret void
}

define i64 @caller_large_struct_ret() nounwind {
  ; LA64-LABEL: name: caller_large_struct_ret
  ; LA64: bb.1 (%ir-block.0):
  ; LA64-NEXT:   [[FRAME_INDEX:%[0-9]+]]:_(p0) = G_FRAME_INDEX %stack.0
  ; LA64-NEXT:   $r4 = COPY [[FRAME_INDEX]](p0)
  ; LA64-NEXT:   PseudoCALL target-flags(loongarch-call-plt) @callee_large_struct_ret, implicit-def $r1, implicit $r4
  ; LA64-NEXT:   [[LOAD:%[0-9]+]]:_(s64) = G_LOAD [[FRAME_INDEX]](p0) :: (dereferenceable load (s64) from %ir.2)
  ; LA64-NEXT:   [[C:%[0-9]+]]:_(s64) = G_CONSTANT i64 24
  ; LA64-NEXT:   %3:_(p0) = nuw nusw G_PTR_ADD [[FRAME_INDEX]], [[C]](s64)
  ; LA64-NEXT:   [[LOAD1:%[0-9]+]]:_(s64) = G_LOAD %3(p0) :: (dereferenceable load (s64) from %ir.4)
  ; LA64-NEXT:   [[ADD:%[0-9]+]]:_(s64) = G_ADD [[LOAD]], [[LOAD1]]
  ; LA64-NEXT:   $r4 = COPY [[ADD]](s64)
  ; LA64-NEXT:   PseudoRET implicit $r4
  %1 = alloca %struct.large
  call void @callee_large_struct_ret(ptr sret(%struct.large) %1)
  %2 = getelementptr inbounds %struct.large, ptr %1, i64 0, i32 0
  %3 = load i64, ptr %2
  %4 = getelementptr inbounds %struct.large, ptr %1, i64 0, i32 3
  %5 = load i64, ptr %4
  %6 = add i64 %3, %5
  ret i64 %6
}
